spark-submit --driver-memory 15g MovieLensALS.py --spark-executor-memory 15g --local-threads 8 --num-partitions 7 --checkpoint-dir /home/maxikov/spark_dir --temp-dir /home/maxikov/spark_dir --persist-dir /home/maxikov/product_regression_all_regression_tree_rank_3_depth_5_features_trim_percentile_90.state --data-path datasets/ml-20m --movies-file datasets/ml-20m/ml-20m.imdb.medium.csv --tvtropes-file datasets/dbtropes/tropes.csv --rank 3 --lmbda 0.01 --num-iter 300 --predict-product-features --metadata-sources years genres average_rating imdb_keywords imdb_producer imdb_director tags tvtropes --drop-rare-features 250 --drop-rare-movies 50 --cross-validation 70 --regression-model regression_tree --nbins 32 --max-depth 5 --features-trim-percentile 90
2017-05-18 20:03:11,985 - __main__ - DEBUG - rank: 3, lmbda: 0.01, num_iter: 300, num_partitions: 7
2017-05-18 20:03:11,985 - __main__ - DEBUG - data_path: datasets/ml-20m, checkpoint_dir: /home/maxikov/spark_dir
2017-05-18 20:03:11,985 - __main__ - DEBUG - Temp dir: /home/maxikov/spark_dir
2017-05-18 20:03:11,985 - __main__ - DEBUG - local_threads: 8
2017-05-18 20:03:11,985 - __main__ - DEBUG - spark_executor_memory: 15g
2017-05-18 20:03:11,985 - __main__ - DEBUG - regression_model: regression_tree
2017-05-18 20:03:11,986 - __main__ - DEBUG - nbins: 32
2017-05-18 20:03:11,986 - __main__ - DEBUG - regression_users: False
2017-05-18 20:03:11,986 - __main__ - DEBUG - predict_product_features: True
2017-05-18 20:03:11,986 - __main__ - DEBUG - metadata_sources: ['years', 'genres', 'average_rating', 'imdb_keywords', 'imdb_producer', 'imdb_director', 'tags', 'tvtropes']
2017-05-18 20:03:11,986 - __main__ - DEBUG - movies_file: datasets/ml-20m/ml-20m.imdb.medium.csv
2017-05-18 20:03:11,986 - __main__ - DEBUG - cross_validation: 70
2017-05-18 20:03:11,986 - __main__ - DEBUG - tvtropes_file: datasets/dbtropes/tropes.csv
2017-05-18 20:03:11,986 - __main__ - DEBUG - features_trim_percentile: 90
2017-05-18 20:03:11,986 - __main__ - DEBUG - drop_missing_movies: False
2017-05-18 20:03:11,986 - __main__ - DEBUG - drop_rare_features: 250
2017-05-18 20:03:11,987 - __main__ - DEBUG - filter_data_set: 10
2017-05-18 20:03:11,987 - __main__ - DEBUG - persist_dir: /home/maxikov/product_regression_all_regression_tree_rank_3_depth_5_features_trim_percentile_90.state, override_args: False
2017-05-18 20:03:11,987 - __main__ - DEBUG - drop_rare_movies: 50
2017-05-18 20:03:11,987 - __main__ - DEBUG - normalize: False
2017-05-18 20:03:11,987 - __main__ - DEBUG - max_depth: 5
2017-05-18 20:03:11,987 - __main__ - DEBUG - /home/maxikov/product_regression_all_regression_tree_rank_3_depth_5_features_trim_percentile_90.state/args.pkl not found, loading new
2017-05-18 20:03:11,988 - __main__ - DEBUG - Storing in /home/maxikov/product_regression_all_regression_tree_rank_3_depth_5_features_trim_percentile_90.state/args.pkl
2017-05-18 20:03:13,241 - __main__ - DEBUG - msep: ,
2017-05-18 20:03:13,241 - __main__ - DEBUG - Loading ratings
2017-05-18 20:03:25,765 - __main__ - DEBUG - Done in 12.523514 seconds
2017-05-18 20:03:25,765 - __main__ - DEBUG - Loading movies
2017-05-18 20:03:27,160 - __main__ - DEBUG - Done in 1.394854 seconds
2017-05-18 20:03:27,160 - __main__ - DEBUG - 26804 movies loaded
2017-05-18 20:04:32,343 - __main__ - DEBUG - 19912669 records in the training set
2017-05-18 20:04:40,750 - __main__ - DEBUG - 26284 unique movies in the training set
2017-05-18 20:04:40,750 - __main__ - DEBUG - Started internal_feature_predictor
2017-05-18 20:04:40,750 - __main__ - DEBUG - Trying to load previous results
2017-05-18 20:04:40,751 - __main__ - DEBUG - /home/maxikov/product_regression_all_regression_tree_rank_3_depth_5_features_trim_percentile_90.state/results.pkl not found
2017-05-18 20:04:40,751 - __main__ - DEBUG - Training the average rating model
2017-05-18 20:05:01,322 - __main__ - DEBUG - Done in 20.571014 seconds
2017-05-18 20:05:01,353 - __main__ - DEBUG - /home/maxikov/product_regression_all_regression_tree_rank_3_depth_5_features_trim_percentile_90.state/als_model.pkl not found, bulding a new model
2017-05-18 20:05:01,353 - __main__ - DEBUG - Training ALS recommender
2017-05-18 20:12:00,390 - __main__ - DEBUG - Done in 419.037067 seconds
2017-05-18 20:12:00,390 - __main__ - DEBUG - Saving model to /home/maxikov/product_regression_all_regression_tree_rank_3_depth_5_features_trim_percentile_90.state/als_model.pkl
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 878,222
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 878,174
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 878,182
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 878,110
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 878,154
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 878,046
May 18, 2017 8:12:02 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 878,074
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 79,188B for [id] INT32: 19,785 values, 79,140B raw, 79,149B comp, 1 pages, encodings: [BIT_PACKED, PLAIN]
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 79,188B for [id] INT32: 19,785 values, 79,140B raw, 79,149B comp, 1 pages, encodings: [BIT_PACKED, PLAIN]
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 79,189B for [id] INT32: 19,785 values, 79,140B raw, 79,150B comp, 1 pages, encodings: [BIT_PACKED, PLAIN]
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 79,188B for [id] INT32: 19,785 values, 79,140B raw, 79,149B comp, 1 pages, encodings: [BIT_PACKED, PLAIN]
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 79,188B for [id] INT32: 19,785 values, 79,140B raw, 79,149B comp, 1 pages, encodings: [BIT_PACKED, PLAIN]
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 359,991B for [features, list, element] DOUBLE: 59,355 values, 482,390B raw, 359,944B comp, 1 pages, encodings: [RLE, PLAIN]
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 360,017B for [features, list, element] DOUBLE: 59,355 values, 482,390B raw, 359,970B comp, 1 pages, encodings: [RLE, PLAIN]
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 359,963B for [features, list, element] DOUBLE: 59,355 values, 482,390B raw, 359,916B comp, 1 pages, encodings: [RLE, PLAIN]
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 79,185B for [id] INT32: 19,784 values, 79,136B raw, 79,146B comp, 1 pages, encodings: [BIT_PACKED, PLAIN]
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 360,006B for [features, list, element] DOUBLE: 59,355 values, 482,390B raw, 359,959B comp, 1 pages, encodings: [RLE, PLAIN]
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 79,184B for [id] INT32: 19,784 values, 79,136B raw, 79,145B comp, 1 pages, encodings: [BIT_PACKED, PLAIN]
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 360,263B for [features, list, element] DOUBLE: 59,355 values, 482,390B raw, 360,216B comp, 1 pages, encodings: [RLE, PLAIN]
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 359,966B for [features, list, element] DOUBLE: 59,352 values, 482,365B raw, 359,919B comp, 1 pages, encodings: [RLE, PLAIN]
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 360,139B for [features, list, element] DOUBLE: 59,352 values, 482,365B raw, 360,092B comp, 1 pages, encodings: [RLE, PLAIN]
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 164,013
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 163,409
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 162,421
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 163,177
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 159,265
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 163,201
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 164,665
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 15,143B for [id] INT32: 3,775 values, 15,100B raw, 15,105B comp, 1 pages, encodings: [BIT_PACKED, PLAIN]
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 66,955B for [features, list, element] DOUBLE: 11,325 values, 92,051B raw, 66,908B comp, 1 pages, encodings: [RLE, PLAIN]
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 15,032B for [id] INT32: 3,747 values, 14,988B raw, 14,994B comp, 1 pages, encodings: [BIT_PACKED, PLAIN]
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 15,099B for [id] INT32: 3,764 values, 15,056B raw, 15,061B comp, 1 pages, encodings: [BIT_PACKED, PLAIN]
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 66,185B for [features, list, element] DOUBLE: 11,241 values, 91,369B raw, 66,138B comp, 1 pages, encodings: [RLE, PLAIN]
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 66,582B for [features, list, element] DOUBLE: 11,292 values, 91,783B raw, 66,535B comp, 1 pages, encodings: [RLE, PLAIN]
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 15,291B for [id] IN2017-05-18 20:12:03,659 - __main__ - DEBUG - /home/maxikov/product_regression_all_regression_tree_rank_3_depth_5_features_trim_percentile_90.state/baseline_predictions.pkl not found, building new predictions
2017-05-18 20:12:03,659 - __main__ - DEBUG - Computing model predictions
2017-05-18 20:12:21,365 - __main__ - DEBUG - Done in 17.705479 seconds
2017-05-18 20:12:21,365 - __main__ - DEBUG - Computing mean error
2017-05-18 20:19:10,270 - __main__ - DEBUG - Done in 408.904955 seconds
2017-05-18 20:19:10,270 - __main__ - DEBUG - Mean error: 0.607030753425, RMSE: 0.79201503875
2017-05-18 20:19:10,307 - __main__ - DEBUG - Original recommender Evaluating the model
2017-05-18 20:19:10,357 - __main__ - DEBUG - Original recommender Bin range: (0.0, 5.5)
2017-05-18 20:32:34,544 - __main__ - DEBUG - Done in 804.235686 seconds
2017-05-18 20:32:34,544 - __main__ - DEBUG - Original recommender Mean error: -0.010086295962, mean absolute error: 0.607030753425
2017-05-18 20:35:00,808 - __main__ - DEBUG - Original recommender RMSE: 0.79201503875, variance explained: 0.466572402055, mean absolute error: 0.607030753425, r2: 0.432887371669
2017-05-18 20:35:00,808 - __main__ - DEBUG - Original recommender MRAE: 0.255938275772
2017-05-18 20:35:00,808 - __main__ - DEBUG - Original recommender Errors histogram: ([-5.5, -5.166666666666667, -4.833333333333333, -4.5, -4.166666666666667, -3.8333333333333335, -3.5, -3.166666666666667, -2.8333333333333335, -2.5, -2.166666666666667, -1.8333333333333335, -1.5, -1.166666666666667, -0.8333333333333339, -0.5, -0.16666666666666696, 0.16666666666666607, 0.5, 0.833333333333333, 1.166666666666666, 1.5, 1.833333333333333, 2.166666666666666, 2.5, 2.833333333333332, 3.166666666666666, 3.5, 3.833333333333332, 4.166666666666666, 4.5, 4.833333333333332, 5.166666666666666, 5.5], [0, 3, 6, 20, 80, 371, 898, 2861, 8659, 27242, 87466, 263852, 698080, 1511054, 2612937, 3578621, 3731581, 2919558, 1889401, 1110211, 631401, 368806, 219097, 126256, 69854, 34881, 13867, 4370, 1038, 165, 28, 5, 0])
2017-05-18 20:35:00,808 - __main__ - DEBUG - Original recommender Absolute errors histogram: ([0.0, 0.16666666666666666, 0.3333333333333333, 0.5, 0.6666666666666666, 0.8333333333333333, 1.0, 1.1666666666666665, 1.3333333333333333, 1.5, 1.6666666666666665, 1.8333333333333333, 2.0, 2.1666666666666665, 2.333333333333333, 2.5, 2.6666666666666665, 2.833333333333333, 3.0, 3.1666666666666665, 3.333333333333333, 3.5, 3.6666666666666665, 3.833333333333333, 4.0, 4.166666666666666, 4.333333333333333, 4.5, 4.666666666666666, 4.833333333333333, 5.0, 5.166666666666666, 5.333333333333333, 5.5], [3731581, 3469270, 3028909, 2512450, 1989888, 1513554, 1107711, 784366, 545115, 374436, 258222, 180077, 126486, 89468, 64030, 46181, 32332, 22648, 15094, 9126, 5639, 3096, 1645, 787, 331, 127, 58, 25, 9, 4, 4, 0, 0])
2017-05-18 20:35:00,808 - __main__ - DEBUG - Original recommender Squared errors histogram: ([0.0, 0.9166666666666666, 1.8333333333333333, 2.75, 3.6666666666666665, 4.583333333333333, 5.5, 6.416666666666666, 7.333333333333333, 8.25, 9.166666666666666, 10.083333333333332, 11.0, 11.916666666666666, 12.833333333333332, 13.75, 14.666666666666666, 15.583333333333332, 16.5, 17.416666666666664, 18.333333333333332, 19.25, 20.166666666666664, 21.083333333333332, 22.0, 22.916666666666664, 23.833333333333332, 24.75, 25.666666666666664, 26.583333333333332, 27.5, 28.416666666666664, 29.333333333333332, 30.25], [15900281, 2316838, 824531, 369998, 193400, 111873, 69034, 44863, 29348, 19594, 12649, 7820, 5012, 3085, 1849, 1127, 636, 323, 190, 94, 51, 29, 15, 16, 4, 3, 2, 1, 2, 1, 0, 0, 0]):
2017-05-18 20:35:00,808 - __main__ - DEBUG - Original recommender Predictions histogram: ([0.0, 0.16666666666666666, 0.3333333333333333, 0.5, 0.6666666666666666, 0.8333333333333333, 1.0, 1.1666666666666665, 1.3333333333333333, 1.5, 1.6666666666666665, 1.8333333333333333, 2.0, 2.1666666666666665, 2.333333333333333, 2.5, 2.6666666666666665, 2.833333333333333, 3.0, 3.1666666666666665, 3.333333333333333, 3.5, 3.6666666666666665, 3.833333333333333, 4.0, 4.166666666666666, 4.333333333333333, 4.5, 4.666666666666666, 4.833333333333333, 5.0, 5.166666666666666, 5.333333333333333, 5.5], [1185, 2172, 4088, 6884, 10925, 17710, 27785, 40771, 59396, 84553, 121320, 172270, 239558, 331403, 455657, 614339, 813356, 1053938, 1327398, 1612489, 1875472, 2063054, 2118325, 1995204, 1695044, 1289472, 876486, 525345, 277095, 126683, 49002, 16327, 4740])
2017-05-18 20:35:00,809 - __main__ - DEBUG - Original recommender Observations histogram: ([0.0, 0.16666666666666666, 0.3333333333333333, 0.5, 0.6666666666666666, 0.8333333333333333, 1.0, 1.1666666666666665, 1.3333333333333333, 1.5, 1.6666666666666665, 1.8333333333333333, 2.0, 2.1666666666666665, 2.333333333333333, 2.5, 2.6666666666666665, 2.833333333333333, 3.0, 3.1666666666666665, 3.333333333333333, 3.5, 3.6666666666666665, 3.833333333333333, 4.0, 4.166666666666666, 4.333333333333333, 4.5, 4.666666666666666, 4.833333333333333, 5.0, 5.166666666666666, 5.333333333333333, 5.5], [0, 0, 0, 237647, 0, 0, 677127, 0, 0, 278250, 0, 0, 1424879, 0, 0, 880397, 0, 0, 4273372, 0, 0, 2192341, 0, 0, 5536793, 0, 0, 1528880, 0, 0, 2882983, 0, 0])
2017-05-18 20:35:00,810 - __main__ - DEBUG - Writing /home/maxikov/product_regression_all_regression_tree_rank_3_depth_5_features_trim_percentile_90.state/baseline_predictions.pkl
2017-05-18 20:42:58,022 - __main__ - DEBUG - Writing /home/maxikov/product_regression_all_regression_tree_rank_3_depth_5_features_trim_percentile_90.state/results.pkl
2017-05-18 20:42:59,613 - __main__ - DEBUG - AAA  baseline_predictions, features: {}
2017-05-18 20:42:59,630 - __main__ - DEBUG - /home/maxikov/product_regression_all_regression_tree_rank_3_depth_5_features_trim_percentile_90.state/trimmed_recommender.pkl or /home/maxikov/product_regression_all_regression_tree_rank_3_depth_5_features_trim_percentile_90.state/results.pkl not found, bulding a new model
2017-05-18 20:42:59,630 - __main__ - DEBUG - Training trimmed recommender
2017-05-18 20:42:59,630 - __main__ - DEBUG - Trimming feature distributions to leave 90% of data
2017-05-18 20:42:59,630 - __main__ - DEBUG - Processing feature 0
2017-05-18 20:43:00,164 - __main__ - DEBUG - 90% of data are between 0.0940250694752 and 1.70044462681, thresholding the rest
2017-05-18 20:43:00,257 - __main__ - DEBUG - 90% of data are between -0.0317272775806 and 2.24130399227, thresholding the rest
2017-05-18 20:43:00,257 - __main__ - DEBUG - Processing feature 1
2017-05-18 20:43:00,766 - __main__ - DEBUG - 90% of data are between 0.867204022408 and 2.26871256828, thresholding the rest
2017-05-18 20:43:00,886 - __main__ - DEBUG - 90% of data are between 0.237162016332 and 1.93230912089, thresholding the rest
2017-05-18 20:43:00,886 - __main__ - DEBUG - Processing feature 2
2017-05-18 20:43:01,492 - __main__ - DEBUG - 90% of data are between -1.37100076675 and 0.497629827261, thresholding the rest
2017-05-18 20:43:01,639 - __main__ - DEBUG - 90% of data are between -1.70468794107 and 0.850771471858, thresholding the rest
2017-05-18 20:43:01,639 - __main__ - DEBUG - Done in 2.008641 seconds
2017-05-18 20:43:01,639 - __main__ - DEBUG - Computing trimmed predictions
2017-05-18 20:43:01,639 - __main__ - DEBUG - Making trimmed features predictions
2017-05-18 20:43:02,711 - __main__ - DEBUG - Done in 1.072158 seconds
2017-05-18 20:43:05,256 - __main__ - DEBUG - Thresholded features recommender Evaluating the model
2017-05-18 20:43:05,281 - __main__ - DEBUG - Thresholded features recommender Bin range: (0.0, 5.5)
2017-05-18 20:56:46,713 - __main__ - DEBUG - Done in 821.456379 seconds
2017-05-18 20:56:46,713 - __main__ - DEBUG - Thresholded features recommender Mean error: 0.00558789336382, mean absolute error: 0.0294851240215
2017-05-18 20:59:10,505 - __main__ - DEBUG - Thresholded features recommender RMSE: 0.115323771348, variance explained: 0.434416761508, mean absolute error: 0.0294851240215, r2: 0.971488942112
2017-05-18 20:59:10,505 - __main__ - DEBUG - Thresholded features recommender MRAE: 0.0151231945598
2017-05-18 20:59:10,506 - __main__ - DEBUG - Thresholded features recommender Errors histogram: ([-5.5, -5.166666666666667, -4.833333333333333, -4.5, -4.166666666666667, -3.8333333333333335, -3.5, -3.166666666666667, -2.8333333333333335, -2.5, -2.166666666666667, -1.8333333333333335, -1.5, -1.166666666666667, -0.8333333333333339, -0.5, -0.16666666666666696, 0.16666666666666607, 0.5, 0.833333333333333, 1.166666666666666, 1.5, 1.833333333333333, 2.166666666666666, 2.5, 2.833333333333332, 3.166666666666666, 3.5, 3.833333333333332, 4.166666666666666, 4.5, 4.833333333333332, 5.166666666666666, 5.5], [0, 0, 0, 0, 0, 0, 1, 2, 4, 22, 89, 389, 1947, 11791, 72736, 413201, 18723148, 507899, 127885, 36931, 11403, 3510, 1149, 386, 129, 36, 9, 1, 1, 0, 0, 0, 0])
2017-05-18 20:59:10,506 - __main__ - DEBUG - Thresholded features recommender Absolute errors histogram: ([0.0, 0.16666666666666666, 0.3333333333333333, 0.5, 0.6666666666666666, 0.8333333333333333, 1.0, 1.1666666666666665, 1.3333333333333333, 1.5, 1.6666666666666665, 1.8333333333333333, 2.0, 2.1666666666666665, 2.333333333333333, 2.5, 2.6666666666666665, 2.833333333333333, 3.0, 3.1666666666666665, 3.333333333333333, 3.5, 3.6666666666666665, 3.833333333333333, 4.0, 4.166666666666666, 4.333333333333333, 4.5, 4.666666666666666, 4.833333333333333, 5.0, 5.166666666666666, 5.333333333333333, 5.5], [18723148, 637687, 283413, 134611, 66010, 32561, 16161, 8598, 4752, 2551, 1348, 780, 458, 255, 153, 81, 52, 26, 12, 7, 3, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])
2017-05-18 20:59:10,506 - __main__ - DEBUG - Thresholded features recommender Squared errors histogram: ([0.0, 0.9166666666666666, 1.8333333333333333, 2.75, 3.6666666666666665, 4.583333333333333, 5.5, 6.416666666666666, 7.333333333333333, 8.25, 9.166666666666666, 10.083333333333332, 11.0, 11.916666666666666, 12.833333333333332, 13.75, 14.666666666666666, 15.583333333333332, 16.5, 17.416666666666664, 18.333333333333332, 19.25, 20.166666666666664, 21.083333333333332, 22.0, 22.916666666666664, 23.833333333333332, 24.75, 25.666666666666664, 26.583333333333332, 27.5, 28.416666666666664, 29.333333333333332, 30.25], [19871214, 31772, 6402, 1885, 750, 328, 165, 66, 42, 22, 12, 5, 4, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]):
2017-05-18 20:59:10,507 - __main__ - DEBUG - Thresholded features recommender Predictions histogram: ([0.0, 0.16666666666666666, 0.3333333333333333, 0.5, 0.6666666666666666, 0.8333333333333333, 1.0, 1.1666666666666665, 1.3333333333333333, 1.5, 1.6666666666666665, 1.8333333333333333, 2.0, 2.1666666666666665, 2.333333333333333, 2.5, 2.6666666666666665, 2.833333333333333, 3.0, 3.1666666666666665, 3.333333333333333, 3.5, 3.6666666666666665, 3.833333333333333, 4.0, 4.166666666666666, 4.333333333333333, 4.5, 4.666666666666666, 4.833333333333333, 5.0, 5.166666666666666, 5.333333333333333, 5.5], [82, 331, 1052, 2671, 5433, 10410, 18501, 30375, 48612, 73900, 111126, 162593, 231870, 328045, 451550, 611639, 813665, 1058658, 1338335, 1632591, 1905269, 2099787, 2159184, 2031891, 1718848, 1294621, 860399, 499124, 250960, 107905, 38541, 11312, 2689])
2017-05-18 20:59:10,507 - __main__ - DEBUG - Thresholded features recommender Observations histogram: ([0.0, 0.16666666666666666, 0.3333333333333333, 0.5, 0.6666666666666666, 0.8333333333333333, 1.0, 1.1666666666666665, 1.3333333333333333, 1.5, 1.6666666666666665, 1.8333333333333333, 2.0, 2.1666666666666665, 2.333333333333333, 2.5, 2.6666666666666665, 2.833333333333333, 3.0, 3.1666666666666665, 3.333333333333333, 3.5, 3.6666666666666665, 3.833333333333333, 4.0, 4.166666666666666, 4.333333333333333, 4.5, 4.666666666666666, 4.833333333333333, 5.0, 5.166666666666666, 5.333333333333333, 5.5], [1185, 2172, 4088, 6884, 10925, 17710, 27785, 40771, 59396, 84553, 121320, 172270, 239558, 331403, 455657, 614339, 813356, 1053938, 1327398, 1612489, 1875472, 2063054, 2118325, 1995204, 1695044, 1289472, 876486, 525345, 277095, 126683, 49002, 16327, 4740])
2017-05-18 20:59:10,508 - __main__ - DEBUG - Done in 970.878039 seconds
2017-05-18 20:59:10,508 - __main__ - DEBUG - Saving model to /home/maxikov/product_regression_all_regression_tree_rank_3_depth_5_features_trim_percentile_90.state/trimmed_recommender.pkl
Traceback (most recent call last):
  File "/mnt/encrypted_data/Dropbox/cmu/foundation_of_privacy/project/fop_qii/MovieLensALS.py", line 491, in <module>
    main()
  File "/mnt/encrypted_data/Dropbox/cmu/foundation_of_privacy/project/fop_qii/MovieLensALS.py", line 435, in main
    train_ratio=args.cross_validation)
  File "/mnt/encrypted_data/Dropbox/cmu/foundation_of_privacy/project/fop_qii/internal_feature_predictor.py", line 1020, in internal_feature_predictor
    baseline_predictions)
  File "/mnt/encrypted_data/Dropbox/cmu/foundation_of_privacy/project/fop_qii/internal_feature_predictor.py", line 773, in load_or_train_trimmed_recommender
    if os.path.exists(fname):
NameError: global name 'fname' is not defined
T32: 3,812 values, 15,248B raw, 15,253B comp, 1 pages, encodings: [BIT_PACKED, PLAIN]
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 67,112B for [features, list, element] DOUBLE: 11,436 values, 92,953B raw, 67,065B comp, 1 pages, encodings: [RLE, PLAIN]
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 15,107B for [id] INT32: 3,766 values, 15,064B raw, 15,069B comp, 1 pages, encodings: [BIT_PACKED, PLAIN]
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 14,691B for [id] INT32: 3,662 values, 14,648B raw, 14,653B comp, 1 pages, encodings: [BIT_PACKED, PLAIN]
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 66,387B for [features, list, element] DOUBLE: 11,298 values, 91,832B raw, 66,340B comp, 1 pages, encodings: [RLE, PLAIN]
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 64,668B for [features, list, element] DOUBLE: 10,986 values, 89,296B raw, 64,621B comp, 1 pages, encodings: [RLE, PLAIN]
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 15,075B for [id] INT32: 3,758 values, 15,032B raw, 15,037B comp, 1 pages, encodings: [BIT_PACKED, PLAIN]
May 18, 2017 8:12:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 66,543B for [features, list, element] DOUBLE: 11,274 values, 91,637B raw, 66,496B comp, 1 pages, encodings: [RLE, PLAIN]
