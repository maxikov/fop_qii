spark-submit --driver-memory 15g MovieLensALS.py --spark-executor-memory 15g --local-threads 8 --num-partitions 7 --checkpoint-dir /home/maxikov/spark_dir --temp-dir /home/maxikov/spark_dir --persist-dir /home/maxikov/product_regression_all_regression_tree_rank_12_depth_5_features_trim_percentile_90.state --data-path datasets/ml-20m --movies-file datasets/ml-20m/ml-20m.imdb.medium.csv --tvtropes-file datasets/dbtropes/tropes.csv --rank 12 --lmbda 0.01 --num-iter 300 --predict-product-features --metadata-sources years genres average_rating imdb_keywords imdb_producer imdb_director tags tvtropes --drop-rare-features 250 --drop-rare-movies 50 --cross-validation 70 --regression-model regression_tree --nbins 32 --max-depth 5 --features-trim-percentile 90
2017-05-19 11:52:04,397 - __main__ - DEBUG - rank: 12, lmbda: 0.01, num_iter: 300, num_partitions: 7
2017-05-19 11:52:04,397 - __main__ - DEBUG - data_path: datasets/ml-20m, checkpoint_dir: /home/maxikov/spark_dir
2017-05-19 11:52:04,397 - __main__ - DEBUG - Temp dir: /home/maxikov/spark_dir
2017-05-19 11:52:04,397 - __main__ - DEBUG - local_threads: 8
2017-05-19 11:52:04,397 - __main__ - DEBUG - spark_executor_memory: 15g
2017-05-19 11:52:04,398 - __main__ - DEBUG - regression_model: regression_tree
2017-05-19 11:52:04,398 - __main__ - DEBUG - nbins: 32
2017-05-19 11:52:04,398 - __main__ - DEBUG - regression_users: False
2017-05-19 11:52:04,398 - __main__ - DEBUG - predict_product_features: True
2017-05-19 11:52:04,398 - __main__ - DEBUG - metadata_sources: ['years', 'genres', 'average_rating', 'imdb_keywords', 'imdb_producer', 'imdb_director', 'tags', 'tvtropes']
2017-05-19 11:52:04,398 - __main__ - DEBUG - movies_file: datasets/ml-20m/ml-20m.imdb.medium.csv
2017-05-19 11:52:04,398 - __main__ - DEBUG - cross_validation: 70
2017-05-19 11:52:04,398 - __main__ - DEBUG - tvtropes_file: datasets/dbtropes/tropes.csv
2017-05-19 11:52:04,399 - __main__ - DEBUG - features_trim_percentile: 90
2017-05-19 11:52:04,399 - __main__ - DEBUG - drop_missing_movies: False
2017-05-19 11:52:04,399 - __main__ - DEBUG - drop_rare_features: 250
2017-05-19 11:52:04,399 - __main__ - DEBUG - filter_data_set: 10
2017-05-19 11:52:04,399 - __main__ - DEBUG - persist_dir: /home/maxikov/product_regression_all_regression_tree_rank_12_depth_5_features_trim_percentile_90.state, override_args: False
2017-05-19 11:52:04,399 - __main__ - DEBUG - drop_rare_movies: 50
2017-05-19 11:52:04,400 - __main__ - DEBUG - normalize: False
2017-05-19 11:52:04,400 - __main__ - DEBUG - max_depth: 5
2017-05-19 11:52:04,400 - __main__ - DEBUG - /home/maxikov/product_regression_all_regression_tree_rank_12_depth_5_features_trim_percentile_90.state/args.pkl not found, loading new
2017-05-19 11:52:04,400 - __main__ - DEBUG - Storing in /home/maxikov/product_regression_all_regression_tree_rank_12_depth_5_features_trim_percentile_90.state/args.pkl
2017-05-19 11:52:05,998 - __main__ - DEBUG - msep: ,
2017-05-19 11:52:05,998 - __main__ - DEBUG - Loading ratings
2017-05-19 11:52:19,137 - __main__ - DEBUG - Done in 13.139420 seconds
2017-05-19 11:52:19,138 - __main__ - DEBUG - Loading movies
2017-05-19 11:52:20,911 - __main__ - DEBUG - Done in 1.773598 seconds
2017-05-19 11:52:20,912 - __main__ - DEBUG - 26804 movies loaded
2017-05-19 11:53:18,498 - __main__ - DEBUG - 19912669 records in the training set
2017-05-19 11:53:25,387 - __main__ - DEBUG - 26284 unique movies in the training set
2017-05-19 11:53:25,387 - __main__ - DEBUG - Started internal_feature_predictor
2017-05-19 11:53:25,387 - __main__ - DEBUG - Trying to load previous results
2017-05-19 11:53:25,387 - __main__ - DEBUG - /home/maxikov/product_regression_all_regression_tree_rank_12_depth_5_features_trim_percentile_90.state/results.pkl not found
2017-05-19 11:53:25,388 - __main__ - DEBUG - Training the average rating model
2017-05-19 11:53:47,605 - __main__ - DEBUG - Done in 22.217617 seconds
2017-05-19 11:53:47,636 - __main__ - DEBUG - /home/maxikov/product_regression_all_regression_tree_rank_12_depth_5_features_trim_percentile_90.state/als_model.pkl not found, bulding a new model
2017-05-19 11:53:47,636 - __main__ - DEBUG - Training ALS recommender
2017-05-19 12:10:08,707 - __main__ - DEBUG - Done in 981.070697 seconds
2017-05-19 12:10:08,707 - __main__ - DEBUG - Saving model to /home/maxikov/product_regression_all_regression_tree_rank_12_depth_5_features_trim_percentile_90.state/als_model.pkl
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 19, 2017 12:10:11 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 1,896,989
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 1,897,003
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 1,896,507
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 1,896,586
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 1,896,873
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 1,896,846
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 1,896,805
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 79,188B for [id] INT32: 19,785 values, 79,140B raw, 79,149B comp, 1 pages, encodings: [PLAIN, BIT_PACKED]
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 79,189B for [id] INT32: 19,785 values, 79,140B raw, 79,150B comp, 1 pages, encodings: [PLAIN, BIT_PACKED]
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 79,188B for [id] INT32: 19,785 values, 79,140B raw, 79,149B comp, 1 pages, encodings: [PLAIN, BIT_PACKED]
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 79,185B for [id] INT32: 19,784 values, 79,136B raw, 79,146B comp, 1 pages, encodings: [PLAIN, BIT_PACKED]
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,462,894B for [features, list, element] DOUBLE: 237,420 values, 1,948,847B raw, 1,462,799B comp, 2 pages, encodings: [PLAIN, RLE]
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,462,492B for [features, list, element] DOUBLE: 237,420 values, 1,948,847B raw, 1,462,397B comp, 2 pages, encodings: [PLAIN, RLE]
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,462,793B for [features, list, element] DOUBLE: 237,420 values, 1,948,847B raw, 1,462,698B comp, 2 pages, encodings: [PLAIN, RLE]
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 79,188B for [id] INT32: 19,785 values, 79,140B raw, 79,149B comp, 1 pages, encodings: [PLAIN, BIT_PACKED]
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 79,188B for [id] INT32: 19,785 values, 79,140B raw, 79,149B comp, 1 pages, encodings: [PLAIN, BIT_PACKED]
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 79,184B for [id] INT32: 19,784 values, 79,136B raw, 79,145B comp, 1 pages, encodings: [PLAIN, BIT_PACKED]
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,462,466B for [features, list, element] DOUBLE: 237,408 values, 1,948,749B raw, 1,462,371B comp, 2 pages, encodings: [PLAIN, RLE]
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,462,696B for [features, list, element] DOUBLE: 237,420 values, 1,948,847B raw, 1,462,601B comp, 2 pages, encodings: [PLAIN, RLE]
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,462,243B for [features, list, element] DOUBLE: 237,420 values, 1,948,847B raw, 1,462,148B comp, 2 pages, encodings: [PLAIN, RLE]
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,462,659B for [features, list, element] DOUBLE: 237,408 values, 1,948,749B raw, 1,462,564B comp, 2 pages, encodings: [PLAIN, RLE]
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 567,920
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 570,744
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 15,032B for [id] INT32: 3,747 values, 14,988B raw, 14,994B comp, 1 pages, encodings: [PLAIN, BIT_PACKED]
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 268,330B for [features, list, element] DOUBLE: 44,964 values, 369,092B raw, 268,283B comp, 1 pages, encodings: [PLAIN, RLE]
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 15,075B for [id] INT32: 3,758 values, 15,032B raw, 15,037B comp, 1 pages, encodings: [PLAIN, BIT_PACKED]
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 269,917B for [features, list, element] DOUBLE: 45,096 values, 370,175B raw, 269,870B comp, 1 pages, encodings: [PLAIN, RLE]
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 575,384
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 571,496
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 15,291B for [id] INT32: 3,812 values, 15,248B raw, 15,253B comp, 1 pages, encodings: [PLAIN, BIT_PACKED]
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 570,672
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 272,015B for [features, list, element] DOUBLE: 45,744 values, 375,494B raw, 271,968B comp, 1 pages, encodings: [PLAIN, RLE]
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 557,392
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.ha2017-05-19 12:10:12,758 - __main__ - DEBUG - /home/maxikov/product_regression_all_regression_tree_rank_12_depth_5_features_trim_percentile_90.state/baseline_predictions.pkl not found, building new predictions
2017-05-19 12:10:12,758 - __main__ - DEBUG - Computing model predictions
2017-05-19 12:10:25,725 - __main__ - DEBUG - Done in 12.966494 seconds
2017-05-19 12:10:25,725 - __main__ - DEBUG - Computing mean error
2017-05-19 12:17:26,941 - __main__ - DEBUG - Done in 421.216330 seconds
2017-05-19 12:17:26,942 - __main__ - DEBUG - Mean error: 0.535924552156, RMSE: 0.702561060109
2017-05-19 12:17:26,964 - __main__ - DEBUG - Original recommender Evaluating the model
2017-05-19 12:17:26,996 - __main__ - DEBUG - Original recommender Bin range: (0.0, 5.5)
2017-05-19 12:31:16,693 - __main__ - DEBUG - Done in 829.728812 seconds
2017-05-19 12:31:16,693 - __main__ - DEBUG - Original recommender Mean error: -0.0102095208113, mean absolute error: 0.535924552156
2017-05-19 12:33:46,893 - __main__ - DEBUG - Original recommender RMSE: 0.702561060109, variance explained: 0.580820026734, mean absolute error: 0.535924552156, r2: 0.553757826487
2017-05-19 12:33:46,893 - __main__ - DEBUG - Original recommender MRAE: 0.218951667671
2017-05-19 12:33:46,893 - __main__ - DEBUG - Original recommender Errors histogram: ([-5.5, -5.166666666666667, -4.833333333333333, -4.5, -4.166666666666667, -3.8333333333333335, -3.5, -3.166666666666667, -2.8333333333333335, -2.5, -2.166666666666667, -1.8333333333333335, -1.5, -1.166666666666667, -0.8333333333333339, -0.5, -0.16666666666666696, 0.16666666666666607, 0.5, 0.833333333333333, 1.166666666666666, 1.5, 1.833333333333333, 2.166666666666666, 2.5, 2.833333333333332, 3.166666666666666, 3.5, 3.833333333333332, 4.166666666666666, 4.5, 4.833333333333332, 5.166666666666666, 5.5], [1, 0, 5, 9, 49, 145, 484, 1475, 4819, 16504, 54814, 175293, 508966, 1260635, 2526558, 3876979, 4264091, 3207596, 1903486, 1017613, 529809, 279333, 147362, 75685, 37159, 15946, 5749, 1680, 366, 51, 7, 0, 0])
2017-05-19 12:33:46,893 - __main__ - DEBUG - Original recommender Absolute errors histogram: ([0.0, 0.16666666666666666, 0.3333333333333333, 0.5, 0.6666666666666666, 0.8333333333333333, 1.0, 1.1666666666666665, 1.3333333333333333, 1.5, 1.6666666666666665, 1.8333333333333333, 2.0, 2.1666666666666665, 2.333333333333333, 2.5, 2.6666666666666665, 2.833333333333333, 3.0, 3.1666666666666665, 3.333333333333333, 3.5, 3.6666666666666665, 3.833333333333333, 4.0, 4.166666666666666, 4.333333333333333, 4.5, 4.666666666666666, 4.833333333333333, 5.0, 5.166666666666666, 5.333333333333333, 5.5], [4264091, 3852561, 3232014, 2537557, 1892487, 1348542, 929706, 624291, 414484, 273397, 181229, 120651, 81525, 55004, 37185, 25328, 16650, 10657, 6764, 3984, 2249, 1213, 612, 294, 121, 43, 17, 7, 5, 0, 0, 0, 1])
2017-05-19 12:33:46,893 - __main__ - DEBUG - Original recommender Squared errors histogram: ([0.0, 0.9166666666666666, 1.8333333333333333, 2.75, 3.6666666666666665, 4.583333333333333, 5.5, 6.416666666666666, 7.333333333333333, 8.25, 9.166666666666666, 10.083333333333332, 11.0, 11.916666666666666, 12.833333333333332, 13.75, 14.666666666666666, 15.583333333333332, 16.5, 17.416666666666664, 18.333333333333332, 19.25, 20.166666666666664, 21.083333333333332, 22.0, 22.916666666666664, 23.833333333333332, 24.75, 25.666666666666664, 26.583333333333332, 27.5, 28.416666666666664, 29.333333333333332, 30.25], [16826773, 1915556, 615580, 257274, 126692, 68863, 39936, 24114, 14826, 9130, 5643, 3436, 2001, 1276, 653, 414, 254, 107, 74, 29, 16, 9, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 1]):
2017-05-19 12:33:46,893 - __main__ - DEBUG - Original recommender Predictions histogram: ([0.0, 0.16666666666666666, 0.3333333333333333, 0.5, 0.6666666666666666, 0.8333333333333333, 1.0, 1.1666666666666665, 1.3333333333333333, 1.5, 1.6666666666666665, 1.8333333333333333, 2.0, 2.1666666666666665, 2.333333333333333, 2.5, 2.6666666666666665, 2.833333333333333, 3.0, 3.1666666666666665, 3.333333333333333, 3.5, 3.6666666666666665, 3.833333333333333, 4.0, 4.166666666666666, 4.333333333333333, 4.5, 4.666666666666666, 4.833333333333333, 5.0, 5.166666666666666, 5.333333333333333, 5.5], [3103, 5475, 10230, 16714, 22876, 34142, 48046, 65523, 87876, 119518, 159364, 214160, 284555, 373541, 491858, 637915, 816558, 1033302, 1262079, 1490451, 1699435, 1850546, 1906506, 1842943, 1631668, 1327639, 986158, 667778, 413295, 231742, 109364, 43170, 14969])
2017-05-19 12:33:46,894 - __main__ - DEBUG - Original recommender Observations histogram: ([0.0, 0.16666666666666666, 0.3333333333333333, 0.5, 0.6666666666666666, 0.8333333333333333, 1.0, 1.1666666666666665, 1.3333333333333333, 1.5, 1.6666666666666665, 1.8333333333333333, 2.0, 2.1666666666666665, 2.333333333333333, 2.5, 2.6666666666666665, 2.833333333333333, 3.0, 3.1666666666666665, 3.333333333333333, 3.5, 3.6666666666666665, 3.833333333333333, 4.0, 4.166666666666666, 4.333333333333333, 4.5, 4.666666666666666, 4.833333333333333, 5.0, 5.166666666666666, 5.333333333333333, 5.5], [0, 0, 0, 237647, 0, 0, 677127, 0, 0, 278250, 0, 0, 1424879, 0, 0, 880397, 0, 0, 4273372, 0, 0, 2192341, 0, 0, 5536793, 0, 0, 1528880, 0, 0, 2882983, 0, 0])
2017-05-19 12:33:46,894 - __main__ - DEBUG - Writing /home/maxikov/product_regression_all_regression_tree_rank_12_depth_5_features_trim_percentile_90.state/baseline_predictions.pkl
2017-05-19 12:41:53,619 - __main__ - DEBUG - Writing /home/maxikov/product_regression_all_regression_tree_rank_12_depth_5_features_trim_percentile_90.state/results.pkl
2017-05-19 12:41:55,219 - __main__ - DEBUG - AAA  baseline_predictions, features: {}
2017-05-19 12:41:55,235 - __main__ - DEBUG - /home/maxikov/product_regression_all_regression_tree_rank_12_depth_5_features_trim_percentile_90.state/trimmed_recommender.pkl or /home/maxikov/product_regression_all_regression_tree_rank_12_depth_5_features_trim_percentile_90.state/results.pkl not found, bulding a new model
2017-05-19 12:41:55,235 - __main__ - DEBUG - Training trimmed recommender
2017-05-19 12:41:55,235 - __main__ - DEBUG - Trimming feature distributions to leave 90% of data
2017-05-19 12:41:55,235 - __main__ - DEBUG - Processing feature 0
2017-05-19 12:41:55,991 - __main__ - DEBUG - 90% of data are between -0.804265129566 and 0.89687128067, thresholding the rest
2017-05-19 12:41:56,126 - __main__ - DEBUG - 90% of data are between -0.605631011724 and 1.01007589102, thresholding the rest
2017-05-19 12:41:56,126 - __main__ - DEBUG - Processing feature 1
2017-05-19 12:41:56,833 - __main__ - DEBUG - 90% of data are between -1.91314034462 and -0.472344225645, thresholding the rest
2017-05-19 12:41:56,996 - __main__ - DEBUG - 90% of data are between -1.61614633203 and -0.300870524347, thresholding the rest
2017-05-19 12:41:56,996 - __main__ - DEBUG - Processing feature 2
2017-05-19 12:41:57,939 - __main__ - DEBUG - 90% of data are between -0.968829739094 and 0.599125313759, thresholding the rest
2017-05-19 12:41:58,138 - __main__ - DEBUG - 90% of data are between -1.06653465629 and 0.473900093138, thresholding the rest
2017-05-19 12:41:58,138 - __main__ - DEBUG - Processing feature 3
2017-05-19 12:41:59,115 - __main__ - DEBUG - 90% of data are between -0.932132983208 and 0.663995933533, thresholding the rest
2017-05-19 12:41:59,343 - __main__ - DEBUG - 90% of data are between -1.08075214624 and 0.493275015056, thresholding the rest
2017-05-19 12:41:59,343 - __main__ - DEBUG - Processing feature 4
2017-05-19 12:42:00,460 - __main__ - DEBUG - 90% of data are between -1.16774802208 and 0.419607210159, thresholding the rest
2017-05-19 12:42:00,714 - __main__ - DEBUG - 90% of data are between -1.23950350881 and 0.315000073612, thresholding the rest
2017-05-19 12:42:00,715 - __main__ - DEBUG - Processing feature 5
2017-05-19 12:42:01,980 - __main__ - DEBUG - 90% of data are between -0.450874221325 and 1.10277285576, thresholding the rest
2017-05-19 12:42:02,256 - __main__ - DEBUG - 90% of data are between -0.356684505939 and 1.30799589753, thresholding the rest
2017-05-19 12:42:02,257 - __main__ - DEBUG - Processing feature 6
2017-05-19 12:42:03,638 - __main__ - DEBUG - 90% of data are between -0.29616804719 and 1.24261727333, thresholding the rest
2017-05-19 12:42:03,949 - __main__ - DEBUG - 90% of data are between -0.370104630291 and 1.14415796995, thresholding the rest
2017-05-19 12:42:03,949 - __main__ - DEBUG - Processing feature 7
2017-05-19 12:42:05,497 - __main__ - DEBUG - 90% of data are between -0.584547507763 and 1.02639575005, thresholding the rest
2017-05-19 12:42:05,835 - __main__ - DEBUG - 90% of data are between -0.707683250308 and 0.872490277886, thresholding the rest
2017-05-19 12:42:05,835 - __main__ - DEBUG - Processing feature 8
2017-05-19 12:42:07,614 - __main__ - DEBUG - 90% of data are between -0.511031103134 and 1.09328107834, thresholding the rest
2017-05-19 12:42:07,970 - __main__ - DEBUG - 90% of data are between -0.425909394026 and 1.12207022905, thresholding the rest
2017-05-19 12:42:07,971 - __main__ - DEBUG - Processing feature 9
2017-05-19 12:42:09,871 - __main__ - DEBUG - 90% of data are between -0.780578017235 and 0.968107497692, thresholding the rest
2017-05-19 12:42:10,269 - __main__ - DEBUG - 90% of data are between -1.09798186421 and 0.519372713566, thresholding the rest
2017-05-19 12:42:10,269 - __main__ - DEBUG - Processing feature 10
2017-05-19 12:42:12,288 - __main__ - DEBUG - 90% of data are between -1.00183391571 and 0.602185809612, thresholding the rest
2017-05-19 12:42:12,702 - __main__ - DEBUG - 90% of data are between -0.765039157867 and 0.823670768738, thresholding the rest
2017-05-19 12:42:12,702 - __main__ - DEBUG - Processing feature 11
2017-05-19 12:42:14,877 - __main__ - DEBUG - 90% of data are between 0.465345150232 and 1.76348602772, thresholding the rest
2017-05-19 12:42:15,353 - __main__ - DEBUG - 90% of data are between 0.0935430254787 and 1.58188234568, thresholding the rest
2017-05-19 12:42:15,353 - __main__ - DEBUG - Done in 20.117747 seconds
2017-05-19 12:42:15,353 - __main__ - DEBUG - Computing trimmed predictions
2017-05-19 12:42:15,353 - __main__ - DEBUG - Making trimmed features predictions
2017-05-19 12:42:19,535 - __main__ - DEBUG - Done in 4.181830 seconds
2017-05-19 12:42:25,371 - __main__ - DEBUG - Thresholded features recommender Evaluating the model
2017-05-19 12:42:25,396 - __main__ - DEBUG - Thresholded features recommender Bin range: (0.0, 5.5)
2017-05-19 12:56:26,557 - __main__ - DEBUG - Done in 841.185619 seconds
2017-05-19 12:56:26,558 - __main__ - DEBUG - Thresholded features recommender Mean error: -0.0166343298011, mean absolute error: 0.0665858285962
2017-05-19 12:58:53,389 - __main__ - DEBUG - Thresholded features recommender RMSE: 0.15021447897, variance explained: 0.515898491964, mean absolute error: 0.0665858285962, r2: 0.961143833202
2017-05-19 12:58:53,390 - __main__ - DEBUG - Thresholded features recommender MRAE: 0.0403699790428
2017-05-19 12:58:53,391 - __main__ - DEBUG - Thresholded features recommender Errors histogram: ([-5.5, -5.166666666666667, -4.833333333333333, -4.5, -4.166666666666667, -3.8333333333333335, -3.5, -3.166666666666667, -2.8333333333333335, -2.5, -2.166666666666667, -1.8333333333333335, -1.5, -1.166666666666667, -0.8333333333333339, -0.5, -0.16666666666666696, 0.16666666666666607, 0.5, 0.833333333333333, 1.166666666666666, 1.5, 1.833333333333333, 2.166666666666666, 2.5, 2.833333333333332, 3.166666666666666, 3.5, 3.833333333333332, 4.166666666666666, 4.5, 4.833333333333332, 5.166666666666666, 5.5], [0, 0, 0, 0, 2, 5, 7, 15, 50, 175, 656, 2164, 8470, 35715, 165511, 1353304, 17452540, 726206, 123645, 29267, 9754, 3454, 1162, 368, 148, 30, 16, 3, 2, 0, 0, 0, 0])
2017-05-19 12:58:53,392 - __main__ - DEBUG - Thresholded features recommender Absolute errors histogram: ([0.0, 0.16666666666666666, 0.3333333333333333, 0.5, 0.6666666666666666, 0.8333333333333333, 1.0, 1.1666666666666665, 1.3333333333333333, 1.5, 1.6666666666666665, 1.8333333333333333, 2.0, 2.1666666666666665, 2.333333333333333, 2.5, 2.6666666666666665, 2.833333333333333, 3.0, 3.1666666666666665, 3.333333333333333, 3.5, 3.6666666666666665, 3.833333333333333, 4.0, 4.166666666666666, 4.333333333333333, 4.5, 4.666666666666666, 4.833333333333333, 5.0, 5.166666666666666, 5.333333333333333, 5.5], [17452540, 1564384, 515126, 199811, 89345, 42921, 22061, 11747, 6477, 3535, 2083, 1179, 639, 336, 207, 129, 69, 26, 19, 14, 9, 6, 2, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0])
2017-05-19 12:58:53,392 - __main__ - DEBUG - Thresholded features recommender Squared errors histogram: ([0.0, 0.9166666666666666, 1.8333333333333333, 2.75, 3.6666666666666665, 4.583333333333333, 5.5, 6.416666666666666, 7.333333333333333, 8.25, 9.166666666666666, 10.083333333333332, 11.0, 11.916666666666666, 12.833333333333332, 13.75, 14.666666666666666, 15.583333333333332, 16.5, 17.416666666666664, 18.333333333333332, 19.25, 20.166666666666664, 21.083333333333332, 22.0, 22.916666666666664, 23.833333333333332, 24.75, 25.666666666666664, 26.583333333333332, 27.5, 28.416666666666664, 29.333333333333332, 30.25], [19855858, 43093, 8847, 2890, 1097, 411, 224, 122, 55, 23, 14, 14, 5, 7, 5, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]):
2017-05-19 12:58:53,393 - __main__ - DEBUG - Thresholded features recommender Predictions histogram: ([0.0, 0.16666666666666666, 0.3333333333333333, 0.5, 0.6666666666666666, 0.8333333333333333, 1.0, 1.1666666666666665, 1.3333333333333333, 1.5, 1.6666666666666665, 1.8333333333333333, 2.0, 2.1666666666666665, 2.333333333333333, 2.5, 2.6666666666666665, 2.833333333333333, 3.0, 3.1666666666666665, 3.333333333333333, 3.5, 3.6666666666666665, 3.833333333333333, 4.0, 4.166666666666666, 4.333333333333333, 4.5, 4.666666666666666, 4.833333333333333, 5.0, 5.166666666666666, 5.333333333333333, 5.5], [699, 1625, 3649, 7372, 13366, 21767, 34951, 52388, 75844, 107316, 149643, 206215, 279452, 374977, 501242, 658391, 849042, 1081210, 1325835, 1570129, 1787699, 1935398, 1975713, 1882168, 1635228, 1291176, 921520, 586895, 330727, 159456, 63194, 20656, 5491])
2017-05-19 12:58:53,393 - __main__ - DEBUG - Thresholded features recommender Observations histogram: ([0.0, 0.16666666666666666, 0.3333333333333333, 0.5, 0.6666666666666666, 0.8333333333333333, 1.0, 1.1666666666666665, 1.3333333333333333, 1.5, 1.6666666666666665, 1.8333333333333333, 2.0, 2.1666666666666665, 2.333333333333333, 2.5, 2.6666666666666665, 2.833333333333333, 3.0, 3.1666666666666665, 3.333333333333333, 3.5, 3.6666666666666665, 3.833333333333333, 4.0, 4.166666666666666, 4.333333333333333, 4.5, 4.666666666666666, 4.833333333333333, 5.0, 5.166666666666666, 5.333333333333333, 5.5], [3103, 5475, 10230, 16714, 22876, 34142, 48046, 65523, 87876, 119518, 159364, 214160, 284555, 373541, 491858, 637915, 816558, 1033302, 1262079, 1490451, 1699435, 1850546, 1906506, 1842943, 1631668, 1327639, 986158, 667778, 413295, 231742, 109364, 43170, 14969])
2017-05-19 12:58:53,396 - __main__ - DEBUG - Done in 1018.161161 seconds
2017-05-19 12:58:53,396 - __main__ - DEBUG - Saving model to /home/maxikov/product_regression_all_regression_tree_rank_12_depth_5_features_trim_percentile_90.state/trimmed_recommender.pkl
Traceback (most recent call last):
  File "/mnt/encrypted_data/Dropbox/cmu/foundation_of_privacy/project/fop_qii/MovieLensALS.py", line 491, in <module>
    main()
  File "/mnt/encrypted_data/Dropbox/cmu/foundation_of_privacy/project/fop_qii/MovieLensALS.py", line 435, in main
    train_ratio=args.cross_validation)
  File "/mnt/encrypted_data/Dropbox/cmu/foundation_of_privacy/project/fop_qii/internal_feature_predictor.py", line 1020, in internal_feature_predictor
    baseline_predictions)
  File "/mnt/encrypted_data/Dropbox/cmu/foundation_of_privacy/project/fop_qii/internal_feature_predictor.py", line 773, in load_or_train_trimmed_recommender
    if os.path.exists(fname):
NameError: global name 'fname' is not defined
doop.ColumnChunkPageWriteStore: written 15,099B for [id] INT32: 3,764 values, 15,056B raw, 15,061B comp, 1 pages, encodings: [PLAIN, BIT_PACKED]
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 270,285B for [features, list, element] DOUBLE: 45,168 values, 370,766B raw, 270,238B comp, 1 pages, encodings: [PLAIN, RLE]
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 15,107B for [id] INT32: 3,766 values, 15,064B raw, 15,069B comp, 1 pages, encodings: [PLAIN, BIT_PACKED]
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 573,840
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 269,054B for [features, list, element] DOUBLE: 45,192 values, 370,963B raw, 269,007B comp, 1 pages, encodings: [PLAIN, RLE]
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 14,691B for [id] INT32: 3,662 values, 14,648B raw, 14,653B comp, 1 pages, encodings: [PLAIN, BIT_PACKED]
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 263,156B for [features, list, element] DOUBLE: 43,944 values, 360,719B raw, 263,109B comp, 1 pages, encodings: [PLAIN, RLE]
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 15,143B for [id] INT32: 3,775 values, 15,100B raw, 15,105B comp, 1 pages, encodings: [PLAIN, BIT_PACKED]
May 19, 2017 12:10:12 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 271,626B for [features, list, element] DOUBLE: 45,300 values, 371,850B raw, 271,579B comp, 1 pages, encodings: [PLAIN, RLE]
