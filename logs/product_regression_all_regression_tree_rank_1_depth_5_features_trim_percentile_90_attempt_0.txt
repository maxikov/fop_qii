spark-submit --driver-memory 15g MovieLensALS.py --spark-executor-memory 15g --local-threads 8 --num-partitions 7 --checkpoint-dir /home/maxikov/spark_dir --temp-dir /home/maxikov/spark_dir --persist-dir /home/maxikov/product_regression_all_regression_tree_rank_1_depth_5_features_trim_percentile_90.state --data-path datasets/ml-20m --movies-file datasets/ml-20m/ml-20m.imdb.medium.csv --tvtropes-file datasets/dbtropes/tropes.csv --rank 1 --lmbda 0.01 --num-iter 300 --predict-product-features --metadata-sources years genres average_rating imdb_keywords imdb_producer imdb_director tags tvtropes --drop-rare-features 250 --drop-rare-movies 50 --cross-validation 70 --regression-model regression_tree --nbins 32 --max-depth 5 --features-trim-percentile 90
2017-05-18 00:12:23,656 - __main__ - DEBUG - rank: 1, lmbda: 0.01, num_iter: 300, num_partitions: 7
2017-05-18 00:12:23,656 - __main__ - DEBUG - data_path: datasets/ml-20m, checkpoint_dir: /home/maxikov/spark_dir
2017-05-18 00:12:23,656 - __main__ - DEBUG - Temp dir: /home/maxikov/spark_dir
2017-05-18 00:12:23,657 - __main__ - DEBUG - local_threads: 8
2017-05-18 00:12:23,657 - __main__ - DEBUG - spark_executor_memory: 15g
2017-05-18 00:12:23,657 - __main__ - DEBUG - regression_model: regression_tree
2017-05-18 00:12:23,657 - __main__ - DEBUG - nbins: 32
2017-05-18 00:12:23,657 - __main__ - DEBUG - regression_users: False
2017-05-18 00:12:23,657 - __main__ - DEBUG - predict_product_features: True
2017-05-18 00:12:23,657 - __main__ - DEBUG - metadata_sources: ['years', 'genres', 'average_rating', 'imdb_keywords', 'imdb_producer', 'imdb_director', 'tags', 'tvtropes']
2017-05-18 00:12:23,657 - __main__ - DEBUG - movies_file: datasets/ml-20m/ml-20m.imdb.medium.csv
2017-05-18 00:12:23,657 - __main__ - DEBUG - cross_validation: 70
2017-05-18 00:12:23,657 - __main__ - DEBUG - tvtropes_file: datasets/dbtropes/tropes.csv
2017-05-18 00:12:23,657 - __main__ - DEBUG - features_trim_percentile: 90
2017-05-18 00:12:23,657 - __main__ - DEBUG - drop_missing_movies: False
2017-05-18 00:12:23,657 - __main__ - DEBUG - drop_rare_features: 250
2017-05-18 00:12:23,657 - __main__ - DEBUG - filter_data_set: 10
2017-05-18 00:12:23,657 - __main__ - DEBUG - persist_dir: /home/maxikov/product_regression_all_regression_tree_rank_1_depth_5_features_trim_percentile_90.state, override_args: False
2017-05-18 00:12:23,658 - __main__ - DEBUG - drop_rare_movies: 50
2017-05-18 00:12:23,658 - __main__ - DEBUG - normalize: False
2017-05-18 00:12:23,658 - __main__ - DEBUG - max_depth: 5
2017-05-18 00:12:23,658 - __main__ - DEBUG - /home/maxikov/product_regression_all_regression_tree_rank_1_depth_5_features_trim_percentile_90.state/args.pkl not found, loading new
2017-05-18 00:12:23,658 - __main__ - DEBUG - Storing in /home/maxikov/product_regression_all_regression_tree_rank_1_depth_5_features_trim_percentile_90.state/args.pkl
2017-05-18 00:12:25,157 - __main__ - DEBUG - msep: ,
2017-05-18 00:12:25,157 - __main__ - DEBUG - Loading ratings
2017-05-18 00:12:37,889 - __main__ - DEBUG - Done in 12.731774 seconds
2017-05-18 00:12:37,889 - __main__ - DEBUG - Loading movies
2017-05-18 00:12:39,309 - __main__ - DEBUG - Done in 1.419375 seconds
2017-05-18 00:12:39,309 - __main__ - DEBUG - 26804 movies loaded
2017-05-18 00:13:40,105 - __main__ - DEBUG - 19912669 records in the training set
2017-05-18 00:13:50,131 - __main__ - DEBUG - 26284 unique movies in the training set
2017-05-18 00:13:50,131 - __main__ - DEBUG - Started internal_feature_predictor
2017-05-18 00:13:50,131 - __main__ - DEBUG - Trying to load previous results
2017-05-18 00:13:50,131 - __main__ - DEBUG - /home/maxikov/product_regression_all_regression_tree_rank_1_depth_5_features_trim_percentile_90.state/results.pkl not found
2017-05-18 00:13:50,131 - __main__ - DEBUG - Training the average rating model
2017-05-18 00:14:10,458 - __main__ - DEBUG - Done in 20.326181 seconds
2017-05-18 00:14:10,484 - __main__ - DEBUG - /home/maxikov/product_regression_all_regression_tree_rank_1_depth_5_features_trim_percentile_90.state/als_model.pkl not found, bulding a new model
2017-05-18 00:14:10,485 - __main__ - DEBUG - Training ALS recommender
2017-05-18 00:19:16,463 - __main__ - DEBUG - Done in 305.978699 seconds
2017-05-18 00:19:16,463 - __main__ - DEBUG - Saving model to /home/maxikov/product_regression_all_regression_tree_rank_1_depth_5_features_trim_percentile_90.state/als_model.pkl
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 395,268
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 395,380
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 395,312
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 395,412
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 395,348
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 395,352
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 395,324
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 79,185B for [id] INT32: 19,784 values, 79,136B raw, 79,146B comp, 1 pages, encodings: [BIT_PACKED, PLAIN]
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 79,184B for [id] INT32: 19,784 values, 79,136B raw, 79,145B comp, 1 pages, encodings: [BIT_PACKED, PLAIN]
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 79,188B for [id] INT32: 19,785 values, 79,140B raw, 79,149B comp, 1 pages, encodings: [BIT_PACKED, PLAIN]
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 114,567B for [features, list, element] DOUBLE: 19,785 values, 158,296B raw, 114,520B comp, 1 pages, encodings: [RLE, PLAIN]
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 114,563B for [features, list, element] DOUBLE: 19,784 values, 158,288B raw, 114,516B comp, 1 pages, encodings: [RLE, PLAIN]
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 114,617B for [features, list, element] DOUBLE: 19,784 values, 158,288B raw, 114,570B comp, 1 pages, encodings: [RLE, PLAIN]
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 79,188B for [id] INT32: 19,785 values, 79,140B raw, 79,149B comp, 1 pages, encodings: [BIT_PACKED, PLAIN]
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 79,189B for [id] INT32: 19,785 values, 79,140B raw, 79,150B comp, 1 pages, encodings: [BIT_PACKED, PLAIN]
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 79,188B for [id] INT32: 19,785 values, 79,140B raw, 79,149B comp, 1 pages, encodings: [BIT_PACKED, PLAIN]
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 79,188B for [id] INT32: 19,785 values, 79,140B raw, 79,149B comp, 1 pages, encodings: [BIT_PACKED, PLAIN]
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 114,480B for [features, list, element] DOUBLE: 19,785 values, 158,296B raw, 114,433B comp, 1 pages, encodings: [RLE, PLAIN]
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 114,428B for [features, list, element] DOUBLE: 19,785 values, 158,296B raw, 114,381B comp, 1 pages, encodings: [RLE, PLAIN]
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 114,499B for [features, list, element] DOUBLE: 19,785 values, 158,296B raw, 114,452B comp, 1 pages, encodings: [RLE, PLAIN]
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 114,499B for [features, list, element] DOUBLE: 19,785 values, 158,296B raw, 114,452B comp, 1 pages, encodings: [RLE, PLAIN]
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.codec.CodecConfig: Compression: SNAPPY
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet block size to 134217728
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet page size to 1048576
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Parquet dictionary page size to 1048576
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Dictionary is on
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Validation is off
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ParquetOutputFormat: Writer version is: PARQUET_1_0
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 73,452
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 15,032B for [id] INT32: 3,747 values, 14,988B raw, 14,994B comp, 1 pages, encodings: [BIT_PACKED, PLAIN]
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 21,378B for [features, list, element] DOUBLE: 3,747 values, 29,990B raw, 21,332B comp, 1 pages, encodings: [RLE, PLAIN]
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 74,140
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 15,143B for [id] INT32: 3,775 values, 15,100B raw, 15,105B comp, 1 pages, encodings: [BIT_PACKED, PLAIN]
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 21,604B for [features, list, element] DOUBLE: 3,775 values, 30,214B raw, 21,558B comp, 1 pages, encodings: [RLE, PLAIN]
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 73,872
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 15,099B for [id] INT32: 3,764 values, 15,056B raw, 15,061B comp, 1 pages, encodings: [BIT_PACKED, PLAIN]
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 21,458B for [features, list, element] DOUBLE: 3,764 values, 30,126B raw, 21,412B comp, 1 pages, encodings: [RLE, PLAIN]
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 71,952
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 73,824
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 14,691B for [id] INT32: 3,662 values, 14,648B raw, 14,653B comp, 1 pages, encodings: [BIT_PACKED, PLAIN]
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStor2017-05-18 00:19:19,954 - __main__ - DEBUG - /home/maxikov/product_regression_all_regression_tree_rank_1_depth_5_features_trim_percentile_90.state/baseline_predictions.pkl not found, building new predictions
2017-05-18 00:19:19,954 - __main__ - DEBUG - Computing model predictions
2017-05-18 00:19:35,650 - __main__ - DEBUG - Done in 15.696084 seconds
2017-05-18 00:19:35,650 - __main__ - DEBUG - Computing mean error
2017-05-18 00:26:06,878 - __main__ - DEBUG - Done in 391.227664 seconds
2017-05-18 00:26:06,878 - __main__ - DEBUG - Mean error: 0.65604159183, RMSE: 0.853405547639
2017-05-18 00:26:06,902 - __main__ - DEBUG - Original recommender Evaluating the model
2017-05-18 00:26:06,929 - __main__ - DEBUG - Original recommender Bin range: (0.0, 5.5)
2017-05-18 00:39:00,007 - __main__ - DEBUG - Done in 773.104823 seconds
2017-05-18 00:39:00,007 - __main__ - DEBUG - Original recommender Mean error: -0.00897538479267, mean absolute error: 0.65604159183
2017-05-18 00:41:12,677 - __main__ - DEBUG - Original recommender RMSE: 0.853405547639, variance explained: 0.366622698516, mean absolute error: 0.65604159183, r2: 0.341564276558
2017-05-18 00:41:12,677 - __main__ - DEBUG - Original recommender MRAE: 0.285212698351
2017-05-18 00:41:12,677 - __main__ - DEBUG - Original recommender Errors histogram: ([-5.5, -5.166666666666667, -4.833333333333333, -4.5, -4.166666666666667, -3.8333333333333335, -3.5, -3.166666666666667, -2.8333333333333335, -2.5, -2.166666666666667, -1.8333333333333335, -1.5, -1.166666666666667, -0.8333333333333339, -0.5, -0.16666666666666696, 0.16666666666666607, 0.5, 0.833333333333333, 1.166666666666666, 1.5, 1.833333333333333, 2.166666666666666, 2.5, 2.833333333333332, 3.166666666666666, 3.5, 3.833333333333332, 4.166666666666666, 4.5, 4.833333333333332, 5.166666666666666, 5.5], [0, 0, 0, 10, 125, 463, 1295, 3765, 10672, 35674, 115904, 339214, 835519, 1650257, 2622181, 3399941, 3454030, 2719003, 1825648, 1135730, 695247, 440912, 280765, 169255, 94865, 49036, 21919, 8147, 2362, 563, 123, 37, 7])
2017-05-18 00:41:12,677 - __main__ - DEBUG - Original recommender Absolute errors histogram: ([0.0, 0.16666666666666666, 0.3333333333333333, 0.5, 0.6666666666666666, 0.8333333333333333, 1.0, 1.1666666666666665, 1.3333333333333333, 1.5, 1.6666666666666665, 1.8333333333333333, 2.0, 2.1666666666666665, 2.333333333333333, 2.5, 2.6666666666666665, 2.833333333333333, 3.0, 3.1666666666666665, 3.333333333333333, 3.5, 3.6666666666666665, 3.833333333333333, 4.0, 4.166666666666666, 4.333333333333333, 4.5, 4.666666666666666, 4.833333333333333, 5.0, 5.166666666666666, 5.333333333333333, 5.5], [3454030, 3239895, 2879049, 2447735, 2000094, 1579937, 1206050, 889572, 641194, 456472, 323654, 231207, 165462, 119360, 85569, 61673, 43864, 31231, 21570, 14309, 8905, 5511, 3099, 1645, 842, 399, 174, 74, 49, 24, 13, 6, 1])
2017-05-18 00:41:12,678 - __main__ - DEBUG - Original recommender Squared errors histogram: ([0.0, 0.9166666666666666, 1.8333333333333333, 2.75, 3.6666666666666665, 4.583333333333333, 5.5, 6.416666666666666, 7.333333333333333, 8.25, 9.166666666666666, 10.083333333333332, 11.0, 11.916666666666666, 12.833333333333332, 13.75, 14.666666666666666, 15.583333333333332, 16.5, 17.416666666666664, 18.333333333333332, 19.25, 20.166666666666664, 21.083333333333332, 22.0, 22.916666666666664, 23.833333333333332, 24.75, 25.666666666666664, 26.583333333333332, 27.5, 28.416666666666664, 29.333333333333332, 30.25], [15234931, 2552948, 986686, 466291, 251202, 148711, 92383, 60134, 39858, 27031, 18365, 12243, 7911, 5203, 3397, 2104, 1317, 739, 496, 280, 174, 88, 55, 39, 22, 26, 13, 7, 7, 6, 1, 1, 0]):
2017-05-18 00:41:12,678 - __main__ - DEBUG - Original recommender Predictions histogram: ([0.0, 0.16666666666666666, 0.3333333333333333, 0.5, 0.6666666666666666, 0.8333333333333333, 1.0, 1.1666666666666665, 1.3333333333333333, 1.5, 1.6666666666666665, 1.8333333333333333, 2.0, 2.1666666666666665, 2.333333333333333, 2.5, 2.6666666666666665, 2.833333333333333, 3.0, 3.1666666666666665, 3.333333333333333, 3.5, 3.6666666666666665, 3.833333333333333, 4.0, 4.166666666666666, 4.333333333333333, 4.5, 4.666666666666666, 4.833333333333333, 5.0, 5.166666666666666, 5.333333333333333, 5.5], [0, 6, 354, 367, 794, 2545, 5654, 9208, 17756, 33506, 61979, 105054, 168707, 267474, 420049, 631409, 894639, 1200027, 1525117, 1832245, 2077236, 2211329, 2184215, 1974685, 1600629, 1157553, 743242, 421670, 210685, 92914, 37958, 14589, 5397])
2017-05-18 00:41:12,678 - __main__ - DEBUG - Original recommender Observations histogram: ([0.0, 0.16666666666666666, 0.3333333333333333, 0.5, 0.6666666666666666, 0.8333333333333333, 1.0, 1.1666666666666665, 1.3333333333333333, 1.5, 1.6666666666666665, 1.8333333333333333, 2.0, 2.1666666666666665, 2.333333333333333, 2.5, 2.6666666666666665, 2.833333333333333, 3.0, 3.1666666666666665, 3.333333333333333, 3.5, 3.6666666666666665, 3.833333333333333, 4.0, 4.166666666666666, 4.333333333333333, 4.5, 4.666666666666666, 4.833333333333333, 5.0, 5.166666666666666, 5.333333333333333, 5.5], [0, 0, 0, 237647, 0, 0, 677127, 0, 0, 278250, 0, 0, 1424879, 0, 0, 880397, 0, 0, 4273372, 0, 0, 2192341, 0, 0, 5536793, 0, 0, 1528880, 0, 0, 2882983, 0, 0])
2017-05-18 00:41:12,679 - __main__ - DEBUG - Writing /home/maxikov/product_regression_all_regression_tree_rank_1_depth_5_features_trim_percentile_90.state/baseline_predictions.pkl
2017-05-18 00:49:02,618 - __main__ - DEBUG - Writing /home/maxikov/product_regression_all_regression_tree_rank_1_depth_5_features_trim_percentile_90.state/results.pkl
2017-05-18 00:49:04,192 - __main__ - DEBUG - AAA  baseline_predictions, features: {}
2017-05-18 00:49:04,210 - __main__ - DEBUG - /home/maxikov/product_regression_all_regression_tree_rank_1_depth_5_features_trim_percentile_90.state/trimmed_recommender.pkl or /home/maxikov/product_regression_all_regression_tree_rank_1_depth_5_features_trim_percentile_90.state/results.pkl not found, bulding a new model
2017-05-18 00:49:04,210 - __main__ - DEBUG - Training trimmed recommender
2017-05-18 00:49:04,210 - __main__ - DEBUG - Trimming feature distributions to leave 90% of data
2017-05-18 00:49:04,210 - __main__ - DEBUG - Processing feature 0
2017-05-18 00:49:04,771 - __main__ - DEBUG - 90% of data are between -2.30955371857 and -1.5866717577, thresholding the rest
2017-05-18 00:49:04,862 - __main__ - DEBUG - 90% of data are between -2.16284275055 and -1.07733905315, thresholding the rest
2017-05-18 00:49:04,862 - __main__ - DEBUG - Done in 0.651986 seconds
2017-05-18 00:49:04,862 - __main__ - DEBUG - Computing trimmed predictions
2017-05-18 00:49:04,863 - __main__ - DEBUG - Making trimmed features predictions
2017-05-18 00:49:05,629 - __main__ - DEBUG - Done in 0.766816 seconds
2017-05-18 00:49:07,507 - __main__ - DEBUG - Thresholded features recommender Evaluating the model
2017-05-18 00:49:07,532 - __main__ - DEBUG - Thresholded features recommender Bin range: (0.0, 5.5)
2017-05-18 01:01:57,557 - __main__ - DEBUG - Done in 770.049083 seconds
2017-05-18 01:01:57,557 - __main__ - DEBUG - Thresholded features recommender Mean error: 0.00918336902554, mean absolute error: 0.0257038341008
2017-05-18 01:04:06,520 - __main__ - DEBUG - Thresholded features recommender RMSE: 0.10975409607, variance explained: 0.321565797397, mean absolute error: 0.0257038341008, r2: 0.967136216393
2017-05-18 01:04:06,521 - __main__ - DEBUG - Thresholded features recommender MRAE: 0.0101803264279
2017-05-18 01:04:06,522 - __main__ - DEBUG - Thresholded features recommender Errors histogram: ([-5.5, -5.166666666666667, -4.833333333333333, -4.5, -4.166666666666667, -3.8333333333333335, -3.5, -3.166666666666667, -2.8333333333333335, -2.5, -2.166666666666667, -1.8333333333333335, -1.5, -1.166666666666667, -0.8333333333333339, -0.5, -0.16666666666666696, 0.16666666666666607, 0.5, 0.833333333333333, 1.166666666666666, 1.5, 1.833333333333333, 2.166666666666666, 2.5, 2.833333333333332, 3.166666666666666, 3.5, 3.833333333333332, 4.166666666666666, 4.5, 4.833333333333332, 5.166666666666666, 5.5], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 24, 490, 5261, 27843, 263020, 18938471, 492112, 118940, 40047, 18603, 5024, 1918, 755, 146, 10, 0, 0, 0, 0, 0, 0, 0])
2017-05-18 01:04:06,522 - __main__ - DEBUG - Thresholded features recommender Absolute errors histogram: ([0.0, 0.16666666666666666, 0.3333333333333333, 0.5, 0.6666666666666666, 0.8333333333333333, 1.0, 1.1666666666666665, 1.3333333333333333, 1.5, 1.6666666666666665, 1.8333333333333333, 2.0, 2.1666666666666665, 2.333333333333333, 2.5, 2.6666666666666665, 2.833333333333333, 3.0, 3.1666666666666665, 3.333333333333333, 3.5, 3.6666666666666665, 3.833333333333333, 4.0, 4.166666666666666, 4.333333333333333, 4.5, 4.666666666666666, 4.833333333333333, 5.0, 5.166666666666666, 5.333333333333333, 5.5], [18938471, 533069, 222063, 99703, 47080, 27799, 17509, 12915, 6178, 3360, 1688, 1242, 681, 674, 81, 85, 61, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])
2017-05-18 01:04:06,522 - __main__ - DEBUG - Thresholded features recommender Squared errors histogram: ([0.0, 0.9166666666666666, 1.8333333333333333, 2.75, 3.6666666666666665, 4.583333333333333, 5.5, 6.416666666666666, 7.333333333333333, 8.25, 9.166666666666666, 10.083333333333332, 11.0, 11.916666666666666, 12.833333333333332, 13.75, 14.666666666666666, 15.583333333333332, 16.5, 17.416666666666664, 18.333333333333332, 19.25, 20.166666666666664, 21.083333333333332, 22.0, 22.916666666666664, 23.833333333333332, 24.75, 25.666666666666664, 26.583333333333332, 27.5, 28.416666666666664, 29.333333333333332, 30.25], [19862504, 37295, 8240, 2467, 1161, 771, 94, 76, 59, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]):
2017-05-18 01:04:06,522 - __main__ - DEBUG - Thresholded features recommender Predictions histogram: ([0.0, 0.16666666666666666, 0.3333333333333333, 0.5, 0.6666666666666666, 0.8333333333333333, 1.0, 1.1666666666666665, 1.3333333333333333, 1.5, 1.6666666666666665, 1.8333333333333333, 2.0, 2.1666666666666665, 2.333333333333333, 2.5, 2.6666666666666665, 2.833333333333333, 3.0, 3.1666666666666665, 3.333333333333333, 3.5, 3.6666666666666665, 3.833333333333333, 4.0, 4.166666666666666, 4.333333333333333, 4.5, 4.666666666666666, 4.833333333333333, 5.0, 5.166666666666666, 5.333333333333333, 5.5], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 37382, 69973, 140715, 235738, 385199, 589478, 885142, 1216855, 1583380, 1953559, 2201383, 2227838, 2206066, 2002615, 1618362, 1162059, 726230, 404146, 183164, 83385, 0, 0, 0])
2017-05-18 01:04:06,522 - __main__ - DEBUG - Thresholded features recommender Observations histogram: ([0.0, 0.16666666666666666, 0.3333333333333333, 0.5, 0.6666666666666666, 0.8333333333333333, 1.0, 1.1666666666666665, 1.3333333333333333, 1.5, 1.6666666666666665, 1.8333333333333333, 2.0, 2.1666666666666665, 2.333333333333333, 2.5, 2.6666666666666665, 2.833333333333333, 3.0, 3.1666666666666665, 3.333333333333333, 3.5, 3.6666666666666665, 3.833333333333333, 4.0, 4.166666666666666, 4.333333333333333, 4.5, 4.666666666666666, 4.833333333333333, 5.0, 5.166666666666666, 5.333333333333333, 5.5], [0, 6, 354, 367, 794, 2545, 5654, 9208, 17756, 33506, 61979, 105054, 168707, 267474, 420049, 631409, 894639, 1200027, 1525117, 1832245, 2077236, 2211329, 2184215, 1974685, 1600629, 1157553, 743242, 421670, 210685, 92914, 37958, 14589, 5397])
2017-05-18 01:04:06,524 - __main__ - DEBUG - Done in 902.313422 seconds
2017-05-18 01:04:06,524 - __main__ - DEBUG - Saving model to /home/maxikov/product_regression_all_regression_tree_rank_1_depth_5_features_trim_percentile_90.state/trimmed_recommender.pkl
Traceback (most recent call last):
  File "/mnt/encrypted_data/Dropbox/cmu/foundation_of_privacy/project/fop_qii/MovieLensALS.py", line 491, in <module>
    main()
  File "/mnt/encrypted_data/Dropbox/cmu/foundation_of_privacy/project/fop_qii/MovieLensALS.py", line 435, in main
    train_ratio=args.cross_validation)
  File "/mnt/encrypted_data/Dropbox/cmu/foundation_of_privacy/project/fop_qii/internal_feature_predictor.py", line 1020, in internal_feature_predictor
    baseline_predictions)
  File "/mnt/encrypted_data/Dropbox/cmu/foundation_of_privacy/project/fop_qii/internal_feature_predictor.py", line 773, in load_or_train_trimmed_recommender
    if os.path.exists(fname):
NameError: global name 'fname' is not defined
e: written 20,890B for [features, list, element] DOUBLE: 3,662 values, 29,310B raw, 20,844B comp, 1 pages, encodings: [RLE, PLAIN]
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 73,768
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 15,107B for [id] INT32: 3,766 values, 15,064B raw, 15,069B comp, 1 pages, encodings: [BIT_PACKED, PLAIN]
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 74,544
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 21,448B for [features, list, element] DOUBLE: 3,766 values, 30,142B raw, 21,402B comp, 1 pages, encodings: [RLE, PLAIN]
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 15,291B for [id] INT32: 3,812 values, 15,248B raw, 15,253B comp, 1 pages, encodings: [BIT_PACKED, PLAIN]
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 15,075B for [id] INT32: 3,758 values, 15,032B raw, 15,037B comp, 1 pages, encodings: [BIT_PACKED, PLAIN]
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 21,634B for [features, list, element] DOUBLE: 3,812 values, 30,510B raw, 21,588B comp, 1 pages, encodings: [RLE, PLAIN]
May 18, 2017 12:19:19 AM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 21,479B for [features, list, element] DOUBLE: 3,758 values, 30,078B raw, 21,433B comp, 1 pages, encodings: [RLE, PLAIN]
